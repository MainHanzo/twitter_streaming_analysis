{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.1.0,org.apache.spark:spark-sql-kafka-0-10_2.11:2.1.0,com.databricks:spark-avro_2.11:3.2.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytwitter import StreamApi\n",
    "import json\n",
    "import os\n",
    "import credentials # Import api/access_token keys from credentials.py\n",
    "import settings # Import related setting constants from settings.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pykafka import KafkaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = KafkaClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = client.topics[\"test1\"].get_producer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStream(StreamApi):\n",
    "    def __init__(self, bearer_token):\n",
    "        try:\n",
    "            StreamApi.__init__(self, bearer_token=bearer_token)\n",
    "            self.__file_index = 0\n",
    "        except KeyError as e:\n",
    "            print(\"error on_tweet: %s\" % str(e))\n",
    "\n",
    "    def on_data(self, raw_data, return_json=False):\n",
    "        # print(tweet)\n",
    "        # tweets_file_path = 'tweets_json/{}.json'.format(self.__file_index)\n",
    "        # with open(tweets_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        #         json.dump(tweet, outfile, ensure_ascii=False)\n",
    "        # while os.path.exists(tweets_file_path) and os.stat(tweets_file_path).st_size > 2**10:\n",
    "        #     self.__file_index += 1 \n",
    "        #     tweets_file_path = 'tweets_json/{}.json'.format(self.__file_index)\n",
    "        data = json.loads(raw_data)\n",
    "        print(data)\n",
    "        tweet_info = {}\n",
    "        try:\n",
    "            tweet_info[\"tweet\"] = data[\"data\"][\"text\"]\n",
    "            tweet_info[\"created_at\"] = data[\"data\"][\"created_at\"]\n",
    "            print(tweet_info)\n",
    "            producer.produce(bytes(json.dumps(tweet_info), \"utf-8\"))\n",
    "        except KeyError as e:\n",
    "            print(\"error on_tweet: %s\" % str(e))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "        \"add\": [\n",
    "            {\"value\": \"cat has:media\", \"tag\": \"cats with media\"},\n",
    "            {\"value\": \"cat has:media -grumpy\", \"tag\": \"happy cats with media\"}\n",
    "        ]\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = MyStream(bearer_token=credentials.BEARER_TOKEN)\n",
    "stream.manage_rules(rules=rules)\n",
    "stream.search_stream(tweet_fields = (\"created_at\"))\n",
    "# stream.sample_stream(return_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
