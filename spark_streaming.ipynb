{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.1.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1 pyspark-shell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/Cellar/apache-spark/3.1.1/libexec/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/yhua/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/yhua/.ivy2/jars\n",
      "org.apache.spark#spark-streaming-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a2905c7d-96f8-4f9a-a21a-da23fc54c751;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-streaming-kafka-0-10_2.12;3.1.1 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.6.0 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.8-1 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.2 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-10_2.12/3.1.1/spark-streaming-kafka-0-10_2.12-3.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-streaming-kafka-0-10_2.12;3.1.1!spark-streaming-kafka-0-10_2.12.jar (289ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.1/spark-sql-kafka-0-10_2.12-3.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1!spark-sql-kafka-0-10_2.12.jar (324ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.1.1/spark-token-provider-kafka-0-10_2.12-3.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1!spark-token-provider-kafka-0-10_2.12.jar (62ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.6.0/kafka-clients-2.6.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.6.0!kafka-clients.jar (3966ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.8-1/zstd-jni-1.4.8-1.jar ...\n",
      "\t[SUCCESSFUL ] com.github.luben#zstd-jni;1.4.8-1!zstd-jni.jar (2157ms)\n",
      "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar ...\n",
      "\t[SUCCESSFUL ] org.lz4#lz4-java;1.7.1!lz4-java.jar (221ms)\n",
      "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.2!snappy-java.jar(bundle) (496ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.30!slf4j-api.jar (26ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.6.2!commons-pool2.jar (70ms)\n",
      ":: resolution report :: resolve 4778ms :: artifacts dl 7624ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.8-1 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.6.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 from central in [default]\n",
      "\torg.apache.spark#spark-streaming-kafka-0-10_2.12;3.1.1 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   10  |   9   |   9   |   0   ||   10  |   9   |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: ERRORS\n",
      "\tServer access error at url https://dl.bintray.com/spark-packages/maven/org/apache/apache/18/apache-18.jar (javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake)\n",
      "\n",
      "\tServer access error at url https://dl.bintray.com/spark-packages/maven/org/apache/spark/spark-parent_2.12/3.1.1/spark-parent_2.12-3.1.1.jar (javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake)\n",
      "\n",
      "\tServer access error at url https://dl.bintray.com/spark-packages/maven/org/slf4j/slf4j-parent/1.7.30/slf4j-parent-1.7.30.jar (javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake)\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tServer access error at url https://dl.bintray.com/spark-packages/maven/org/apache/commons/commons-parent/48/commons-parent-48.jar (javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake)\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a2905c7d-96f8-4f9a-a21a-da23fc54c751\n",
      "\tconfs: [default]\n",
      "\t9 artifacts copied, 1 already retrieved (13219kB/21ms)\n",
      "22/09/06 21:45:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/09/06 21:45:18 WARN StreamingContext: spark.master should be set as local[n], n > 1 in local mode if you have receivers to get data, otherwise Spark jobs will not get resources to process the received data.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[1]') \\\n",
    "                    .appName('tweets') \\\n",
    "                    .getOrCreate()\n",
    "ssc = StreamingContext(spark.sparkContext, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-pro-2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>tweets</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbbe602eb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/06 21:46:36 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/xz/v6q9ksld1134sh8phtl83fqc0000gn/T/temporary-87885c6e-5aba-4ac0-84d9-fc8af54b2792. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "|key|value|topic|partition|offset|timestamp|timestampType|\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----+-------------+-----+---------+------+--------------------+-------------+\n",
      "| key|        value|topic|partition|offset|           timestamp|timestampType|\n",
      "+----+-------------+-----+---------+------+--------------------+-------------+\n",
      "|null|[64 64 64 64]|test1|        0|     2|2022-09-06 21:46:...|            0|\n",
      "+----+-------------+-----+---------+------+--------------------+-------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----+-----+-----+---------+------+--------------------+-------------+\n",
      "| key|value|topic|partition|offset|           timestamp|timestampType|\n",
      "+----+-----+-----+---------+------+--------------------+-------------+\n",
      "|null| [61]|test1|        0|     3|2022-09-06 21:47:...|            0|\n",
      "+----+-----+-----+---------+------+--------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xz/v6q9ksld1134sh8phtl83fqc0000gn/T/ipykernel_21225/1268710115.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"console\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/06 22:36:18 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1807609 ms exceeds timeout 120000 ms\n",
      "22/09/06 22:36:18 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "22/09/07 07:13:39 WARN KafkaOffsetReaderConsumer: Error in attempt 1 getting Kafka offsets: \n",
      "org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition test1-0 could be determined\n",
      "22/09/08 04:00:53 WARN KafkaOffsetReaderConsumer: Error in attempt 1 getting Kafka offsets: \n",
      "org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition test1-0 could be determined\n",
      "22/09/08 22:25:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2: nodename nor servname provided, or not known\n",
      "\tat java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928)\n",
      "\tat java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323)\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1276)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.trySend(ConsumerNetworkClient.java:498)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:255)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1760)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1718)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$fetchLatestOffsets$7(KafkaOffsetReaderConsumer.scala:347)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.mutable.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:48)\n",
      "\tat scala.collection.SetLike.map(SetLike.scala:104)\n",
      "\tat scala.collection.SetLike.map$(SetLike.scala:104)\n",
      "\tat scala.collection.mutable.AbstractSet.map(Set.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$fetchLatestOffsets$1(KafkaOffsetReaderConsumer.scala:347)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:545)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:25:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2-4, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-2] Error connecting to node macbook-pro-2:9092 (id: 2147483647 rack: null)\n",
      "java.net.UnknownHostException: macbook-pro-2\n",
      "\tat java.net.InetAddress.getAllByName0(InetAddress.java:1280)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1192)\n",
      "\tat java.net.InetAddress.getAllByName(InetAddress.java:1126)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:294)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:575)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:816)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:796)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)\n",
      "\tat org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)\n",
      "\tat org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:237)\n",
      "\tat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:485)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1268)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$2(KafkaOffsetReaderConsumer.scala:533)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$withRetriesWithoutInterrupt$1(KafkaOffsetReaderConsumer.scala:578)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.withRetriesWithoutInterrupt(KafkaOffsetReaderConsumer.scala:577)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.$anonfun$partitionsAssignedToConsumer$1(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.util.UninterruptibleThreadRunner.runUninterruptibly(UninterruptibleThreadRunner.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.partitionsAssignedToConsumer(KafkaOffsetReaderConsumer.scala:531)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderConsumer.fetchLatestOffsets(KafkaOffsetReaderConsumer.scala:311)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:87)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$3(MicroBatchExecution.scala:394)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:385)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:128)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:382)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:613)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:378)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "22/09/08 22:56:05 WARN KafkaOffsetReaderConsumer: Error in attempt 1 getting Kafka offsets: \n",
      "org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition test1-0 could be determined\n",
      "22/09/09 02:59:21 WARN KafkaOffsetReaderConsumer: Error in attempt 1 getting Kafka offsets: \n",
      "org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition test1-0 could be determined\n",
      "22/09/09 10:04:23 WARN KafkaOffsetReaderConsumer: Error in attempt 1 getting Kafka offsets: \n",
      "org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition test1-0 could be determined\n",
      "22/09/10 21:51:25 WARN KafkaOffsetReaderConsumer: Error in attempt 1 getting Kafka offsets: \n",
      "org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition test1-0 could be determined\n",
      "22/09/11 11:44:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 2147483647 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:44:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:01 WARN KafkaOffsetReaderConsumer: Error in attempt 1 getting Kafka offsets: \n",
      "org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition test1-0 could be determined\n",
      "22/09/11 11:45:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6-8, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-6] Connection to node 0 (macbook-pro-2/192.168.1.32:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:45:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:45:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n",
      "22/09/11 11:46:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "22/09/11 11:46:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7-9, groupId=spark-kafka-source-2b7a0721-a71b-45bf-a3f5-d9fad45d0109--1803746445-driver-7] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected\n"
     ]
    }
   ],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", \"test1\") \\\n",
    "  .load()\n",
    "\n",
    "query = df.writeStream \\\n",
    "  .outputMode(\"append\") \\\n",
    "  .format(\"console\")\\\n",
    "  .start()\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.textFileStream(\"./tweets_json/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strArray = \"Hello World Hello Hadoop Hello spark kafka hive zookeeper hbase flume sqoop scala\".split()\n",
    "strArrayZipped = list(enumerate(strArray))\n",
    "# print(list(map(lambda x: f\"{x[0]} {x[1]}\", strArrayZipped)))\n",
    "strArrayTimestamped = list(map(lambda x: f\"{x[0]} {x[1]}\", strArrayZipped))\n",
    "rdd = ssc.sparkContext.parallelize(strArrayTimestamped, len(strArrayTimestamped))\n",
    "rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStream = ssc.queueStream(rdds=[rdd])\n",
    "counts = dStream.flatMap(lambda line: line.split(\" \"))\\\n",
    "                     .map(lambda word: (word, 1))\\\n",
    "                     .reduceByKey(lambda a, b: a+b)\n",
    "counts.pprint(50)\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "ssc.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val strArray = \"Hello World Hello Hadoop Hello spark kafka hive zookeeper hbase flume sqoop scala\"\n",
    "      .split(\"\\\\s+\")\n",
    "      .zipWithIndex\n",
    "      .map{case (word,timestamp) => s\"$timestamp $word\"}\n",
    "val rdd: RDD[String] = ssc.sparkContext.makeRDD(strArray)\n",
    "\n",
    "    val wordCountStream: ConstantInputDStream[String] = new ConstantInputDStream(ssc,rdd)\n",
    "\n",
    "    // 流式数据的处理\n",
    "    wordCountStream.transform{\n",
    "      rdd=>\n",
    "      rdd.map{line => (line.split(\"\\\\s+\")(1).toLowerCase,line)}  //考虑等值连接时的大小写问题\n",
    "          .leftOuterJoin(blackListRDD)//不用等值连接，因为数据中不一定有黑名单中的词，用左外连接，因为把数据的单词都列出来\n",
    "          .filter{case (_,(_,rightValue)) => !rightValue.getOrElse(false)}//左外连接的结果里，如果没有连接上就显示None, getOrElse(false)： 取出来就是true，取不处来的就是None，给它一个值false\n",
    "          .map{case (_,(leftValue,_)) => leftValue}//把过滤的结果进行筛选，只需要（时间戳，单词）这样的数据形式\n",
    "    }.print(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
